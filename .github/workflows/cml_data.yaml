name: CML Data Pipeline

on:
  push:
    paths:
      - "data/**"  # Trigger on changes to data directory
  pull_request:
    paths:
      - "data/**"

jobs:
  preprocess_data:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Check out the code
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Step 3: Run preprocessing script
      - name: Run dataset preprocessing
        run: |
          python src/cleaninbox/data.py preprocess --config-path configs --config-name config.yaml

      # Step 4: Validate processed data
      - name: Validate processed data
        run: |
          test -f data/processed/train_text.pt || { echo "Processed training data not found"; exit 1; }
          test -f data/processed/test_text.pt || { echo "Processed test data not found"; exit 1; }
          test -f data/processed/label_strings.json || { echo "Label strings file not found"; exit 1; }

      # Step 5: Run tests
      - name: Run tests
        run: |
          pip install pytest
          pytest tests/ --disable-warnings

      # Step 6: Upload processed data artifacts (optional)
      - name: Upload processed data
        uses: actions/upload-artifact@v3
        with:
          name: processed-data
          path: data/processed

      # Step 7: Report statistics with CML
      - name: CML Dataset Report
        run: |
          pip install cml
          cml comment create --publish --file ./logs/preprocessing.log
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
