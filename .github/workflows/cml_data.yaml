name: CML Data Workflow

on:
  push:
    branches:
      - main
    paths:
      - '**/*.dvc'
      - 'dvc.lock'
      - 'data/**'

jobs:
  data-workflow:
    permissions:
      contents: 'read'
      id-token: 'write'
    runs-on: ${{ matrix.operating-system }}
    strategy:
      fail-fast: false
      matrix:
        operating-system: ["ubuntu-latest"]
        python-version: ["3.11"]

    steps:
      # Step 1: Checkout code
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: setup.py

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install -U pip setuptools wheel
          pip install -r requirements.txt
          pip install google-cloud-storage google-cloud-aiplatform torch dvc[all]
          pip list

      # Step 4: Authenticate with Google Cloud (Optional)
      - uses: 'google-github-actions/auth@v2'
        with:
          project_id: 'cleaninbox-448011'
          workload_identity_provider: projects/170780472924/locations/global/workloadIdentityPools/github/providers/my-repo
          service_account: 'dvc-ci@cleaninbox-448011.iam.gserviceaccount.com'

      # Step 5: Pull data using DVC
      - name: Pull data with DVC
        run: |
          dvc pull
          ls -la

      # # Step 6: Debug missing data folder (Optional)
      # - name: Debug missing data folder
      #   run: |
      #     find . -type d -name "data"
      #     pwd

      - name: Compute dataset statistics
        run: |
          python compute_statistics.py
      # # # Step 8: Deploy results (Optional)
      # # - name: Deploy results to the cloud
      # #   run: |
      # #     python deploy.py
